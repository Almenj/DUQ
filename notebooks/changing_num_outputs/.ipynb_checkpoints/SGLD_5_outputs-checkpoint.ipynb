{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812df3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('../../duq/')  \n",
    "import post, pre\n",
    "import sgld as SG\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Suppresses sklearn warning about PCA.. Is this ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234                  # Assign a value to the seed\n",
    "pre.set_seed(seed)      # Set the seed for 'random', 'np.random', 'torch.manual_seed' and 'torch.cuda.manual_seed_all'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60933b74",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b9dbe",
   "metadata": {},
   "source": [
    "## Import, Pre-process and Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde120a",
   "metadata": {},
   "source": [
    "## Splitting Test Set from Main Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4accb3b",
   "metadata": {},
   "source": [
    "This code imports the full dataset in `csv` format for analysis. \n",
    "\n",
    "The user can choose which frequency to predict by changing `y_cols` here. More than one frequency can be in this list, however some of the plotting functions need to be changed slightly. See `MC_Dropout_multi_output.ipynb` for an example of predicting multiple frequencies. \n",
    "\n",
    "The column headings (and corresponding indices) are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087edf34",
   "metadata": {},
   "source": [
    "| num_x | num_y | num_z | width_x | width_y | width_z | freq1 | freq2 | freq3 | freq4 | freq5 | freq6 |\n",
    "| :- | :- | :- | :- | :- | :- | :- | :- | :- | :- | :- | :- |\n",
    "| [0] | [1] | [2] | [3] | [4] | [5] | [6] | [7] | [8] | [9] | [10] | [11] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = [6, 7, 8, 9, 10]             # Which column(s) does the the dependent variable(s) that we're interested in sit? list\n",
    "x_cols = [0,1,2,3,4,5]   # Which column(s) is the independent variable(s) (features) in? list\n",
    "component = \"n/a\"        # this is used if we want to sort and split the data by a particular parameter\n",
    "\n",
    "# Import the csv file and save as DataFrame\n",
    "filepath = '../../data/all_data.csv'\n",
    "df_orig = pd.read_csv(filepath, header=None)\n",
    "df_orig.columns = ['nbays_x', 'nbays_y', 'nbays_z', 'bay_width_x', 'bay_width_y', 'bay_width_z', 'modal_freq_1', 'modal_freq_2', 'modal_freq_3', 'modal_freq_4', 'modal_freq_5', 'modal_freq_6']\n",
    "\n",
    "# Calculate the mean and standard deviation of the original dataset\n",
    "data_mean = df_orig.mean()\n",
    "data_std = df_orig.std()\n",
    "\n",
    "# Visualise full dataset in reduced dimensional space \n",
    "_, components = post.PCA_transformdata(df_orig.iloc[:,x_cols], return_components=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d95ce",
   "metadata": {},
   "source": [
    "## Split Data into Test, Train, Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e54f97",
   "metadata": {},
   "source": [
    "All data within the specified `train_lims_all` gets put into a training set. Then a proportion `val_split` of the training set gets put into a validation set. \n",
    "\n",
    "Anything within the regions specified by `ood_lims_in` and `ood_lims_out` goes in the inner OOD and outer OOD regions respectively. These are then combined to make a test set. \n",
    "\n",
    "The datasets are then normalised and an additional column is added that contains the L2 distance of each point from the geometric median point. \n",
    "\n",
    "Each input parameter (i.e. columns 1 to 6) is plotted in reduced dimensional space for visualisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b582a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_lims_in = [[0., 3.], [0., 3.], [0., 3.], [0., 5.], [0., 5.], [0., 5.]]\n",
    "train_lims_all = [[3., 10], [3., 10], [3., 10], [5., 10], [5., 10], [5., 10]]\n",
    "ood_lims_out = [[10, 25], [10, 25], [10, 30], [10, 12], [10, 12], [10, 12]]\n",
    "\n",
    "TRAIN, VAL, TEST = pre.split_by_bounds(df=df_orig,\n",
    "                                 x_cols=x_cols,\n",
    "                                 y_cols=y_cols,\n",
    "                                 train_lims_all=train_lims_all,\n",
    "                                 ood_lims_in=ood_lims_in,\n",
    "                                 ood_lims_out=ood_lims_out,\n",
    "                                 data_mean=data_mean, \n",
    "                                 data_std=data_std, \n",
    "                                 PCA_components=components,\n",
    "                                 val_split=0.1,\n",
    "                                 verbose=True,\n",
    "                                 plots=True,\n",
    "                                 figsize=(10,10))#,\n",
    "                                      #save_image=True, savename=\"../reports/final_report_images/splitting_data/manual_bounds.eps\", saveformat=\"eps\")\n",
    "\n",
    "x_train, y_train, train_data, train_indices = TRAIN\n",
    "x_val, y_val, val_data, val_indices = VAL\n",
    "x_test, y_test, test_data, test_indices = TEST\n",
    "\n",
    "y_train_unnorm = pre.unnormalise(y_train,data_mean[y_cols].values,data_std[y_cols].values)\n",
    "y_val_unnorm = pre.unnormalise(y_val,data_mean[y_cols].values,data_std[y_cols].values)\n",
    "y_test_unnorm = pre.unnormalise(y_test,data_mean[y_cols].values,data_std[y_cols].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd27bfd4",
   "metadata": {},
   "source": [
    "# Neural Network Instantiation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdd600",
   "metadata": {},
   "source": [
    "## Define Parameters of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12038a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model so we can load it and perform inference later\n",
    "#savename = \"../trained_models/for_prediction/MC_35\"\n",
    "#checkpoint_path = \"../../trained_models/for_retraining/SGLD\"\n",
    "\n",
    "# Define the wandb parameters\n",
    "parameters = dict(\n",
    "    # Specific to this method\n",
    "    noise_multiplier=1,\n",
    "    anneal_gamma = None,\n",
    "    burnin_epochs=250,\n",
    "    num_networks=150,\n",
    "    \n",
    "    # Generic Hyperparameters\n",
    "    num_epochs= 1000,\n",
    "    batch_size= 50,# len(train_data), # Batch size for training data\n",
    "    lr=  1e-3,                   # Learning rate\n",
    "    weight_decay= None,          # Weight decay\n",
    "    \n",
    "    # Model architecture\n",
    "    input_dim= len(x_cols),      # Number of input neurons\n",
    "    output_dim= len(y_cols),     # Number of output neurons\n",
    "    num_units= 50,              # Number of neurons per hidden layer\n",
    "    num_layers=4,\n",
    "    \n",
    "    # Data\n",
    "    y_cols = y_cols,             # Which column(s) contain the dependent variable(s) / label(s) \n",
    "    x_cols = x_cols,             # Which column(s) contain the independent variable(s) / feature(s)\n",
    "    \n",
    "    # Logigng only\n",
    "    component = None,       # Which parameter are we sorting by (as an int)? \n",
    "    sortby=None,       # Name of the component we're sorting by (as a string)\n",
    "    model_name= \"SGLD_5_outputs\",    # For logging only\n",
    "    criterion_name= \"MSELoss\",   # For logging only\n",
    "    optimiser_name= \"Adam\",      # For logging only \n",
    "    cutoff_percentile = None,  # How much we're splitting from top and bottom of sorted training set for test set \n",
    "    val_split=None,         # How much we're splitting from the train set (minus the test set), as a float between 0-1\n",
    "    seed=seed,                   # Random seed used (for logging only)\n",
    ")\n",
    "\n",
    "assert parameters['output_dim'] == len(y_cols), f\"Please ensure that the number of output neurons is correct! There should be {len(y_cols)}\"\n",
    "assert parameters['input_dim'] == len(x_cols), f\"Please ensure that the number of input neurons is correct! There should be {len(x_cols)}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2229ec6",
   "metadata": {},
   "source": [
    "## If using Weights and Biases API, Log In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a176df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Whether or not to log the run to Weights and Biases (https://wandb.ai/home). Requires an account\n",
    "wandb_mode = True\n",
    "\n",
    "if wandb_mode: \n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    wandb.init(config=parameters, entity=\"archieluxton\", project=parameters['model_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0406d1c8",
   "metadata": {},
   "source": [
    "## Instantiate the Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b80d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model class of type MC Dropout\n",
    "model = SG.SGLD(train_data = train_data,\n",
    "                              parameters=parameters, \n",
    "                              val_data=val_data,\n",
    "                              data_mean=data_mean,\n",
    "                              data_std=data_std,\n",
    "                              wandb_mode=wandb_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ceb526",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74fd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "net, train_loss, val_loss = model.train_model()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end-start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cbddee",
   "metadata": {},
   "source": [
    "# Perform Forward Passes for each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b14c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train, means_train, stds_train, y_train_np = model.run_sampling(x_train, y_train)\n",
    "samples_test, means_test, stds_test, y_test_np = model.run_sampling(x_test, y_test)             \n",
    "samples_val, means_val, stds_val, y_val_np = model.run_sampling(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847dbc5f",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Post-Processing and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8420db",
   "metadata": {},
   "source": [
    "## Count number of 'untrustworthy' predictions\n",
    "This function checks how many of the true values in each dataset (test, train, val) fall outside the confidence interval.\n",
    "\n",
    "It does *not* tell us how accurate the mean predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcbef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_untrustworthyness(samples_train, samples_test, samples_val, y_train_np, y_test_np, y_val_np):\n",
    "    err_train0 = post.count_wrong_preds(samples_train, y_train_np, 1, \"SD\", False)\n",
    "    err_test0 = post.count_wrong_preds(samples_test, y_test_np, 1, \"SD\", False)\n",
    "    err_val0 = post.count_wrong_preds(samples_val, y_val_np, 1, \"SD\", False)\n",
    "\n",
    "    print(f\"Untrustworthy in train:\\t{np.sum(err_train0)}\\t(low: {err_train0[0]}, high: {err_train0[1]})\")\n",
    "    print(f\"Untrustworthy in test:\\t{np.sum(err_test0)}\\t(low: {err_test0[0]}, high: {err_test0[1]})\")\n",
    "    print(f\"Untrustworthy in val:\\t{np.sum(err_val0)}\\t(low: {err_val0[0]}, high: {err_val0[1]})\")\n",
    "    print(\"----------------------\")\n",
    "    print(f\"Total untrustworthy:\\t{np.sum(err_train0)+np.sum(err_test0)+np.sum(err_val0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_cols)):\n",
    "    print(f\"OUTPUT {i}:\")\n",
    "    print_untrustworthyness(samples_train[i], samples_test[i], samples_val[i], y_train_np[i], y_test_np[i], y_val_np[i])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a117c",
   "metadata": {},
   "source": [
    "## Plot the Uncertainty of Each Datapoint (Train, Test and Val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae10449",
   "metadata": {},
   "source": [
    "The plot below shows us intuitively what the accuracy and uncertainty of predictions in each dataset is. From this, it's clear to see that the prediction accuracy is high in the training and validation set, and both the accuracy and certainty in the test set are low as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13abce95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uncert_plot = post.result_plots(all_samples = [samples_val, samples_train, samples_test],\n",
    "             labels = [\"Validation\", \"Train\", \"Test (OoD)\"],\n",
    "             output_labels = [\"freq1\", \"freq2\"],\n",
    "             all_true = [y_val_np, y_train_np, y_test_np],\n",
    "             output_num=0,\n",
    "             #true_inds = [val_indices, train_indices, test_indices],\n",
    "             interval = 1,\n",
    "             method=\"SD\",\n",
    "             component_name = parameters[\"component\"],\n",
    "             sort=True,\n",
    "             sortby=\"0\",\n",
    "             bar_method=\"bars\",\n",
    "             title=\"SGLD, Tuned Model\",\n",
    "             ylabel=\"First Modal Frequency (Hz)\",\n",
    "              figsize=(15,10.5),\n",
    "             ylim=(-0.5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0428e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncert_plot = post.result_plots(all_samples = [samples_val, samples_train, samples_test],\n",
    "             labels = [\"Validation\", \"Train\", \"Test (OoD)\"],\n",
    "             output_labels = [\"freq1\", \"freq2\"],\n",
    "             all_true = [y_val_np, y_train_np, y_test_np],\n",
    "             output_num=1,\n",
    "             #true_inds = [val_indices, train_indices, test_indices],\n",
    "             interval = 1,\n",
    "             method=\"SD\",\n",
    "             component_name = parameters[\"component\"],\n",
    "             sort=True,\n",
    "             sortby=\"0\",\n",
    "             bar_method=\"bars\",\n",
    "             title=\"SGLD, Tuned Model\",\n",
    "             ylabel=\"First Modal Frequency (Hz)\",\n",
    "              figsize=(15,10.5),\n",
    "             ylim=(-0.5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncert_plot = post.result_plots(all_samples = [samples_val, samples_train, samples_test],\n",
    "             labels = [\"Validation\", \"Train\", \"Test (OoD)\"],\n",
    "             output_labels = [\"freq1\", \"freq2\"],\n",
    "             all_true = [y_val_np, y_train_np, y_test_np],\n",
    "             output_num=2,\n",
    "             #true_inds = [val_indices, train_indices, test_indices],\n",
    "             interval = 1,\n",
    "             method=\"SD\",\n",
    "             component_name = parameters[\"component\"],\n",
    "             sort=True,\n",
    "             sortby=\"0\",\n",
    "             bar_method=\"bars\",\n",
    "             title=\"SGLD, Tuned Model\",\n",
    "             ylabel=\"First Modal Frequency (Hz)\",\n",
    "              figsize=(15,10.5),\n",
    "             ylim=(-0.5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncert_plot = post.result_plots(all_samples = [samples_val, samples_train, samples_test],\n",
    "             labels = [\"Validation\", \"Train\", \"Test (OoD)\"],\n",
    "             output_labels = [\"freq1\", \"freq2\"],\n",
    "             all_true = [y_val_np, y_train_np, y_test_np],\n",
    "             output_num=3,\n",
    "             #true_inds = [val_indices, train_indices, test_indices],\n",
    "             interval = 1,\n",
    "             method=\"SD\",\n",
    "             component_name = parameters[\"component\"],\n",
    "             sort=True,\n",
    "             sortby=\"0\",\n",
    "             bar_method=\"bars\",\n",
    "             title=\"SGLD, Tuned Model\",\n",
    "             ylabel=\"First Modal Frequency (Hz)\",\n",
    "              figsize=(15,10.5),\n",
    "             ylim=(-0.5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e74327",
   "metadata": {},
   "source": [
    "### Ridgeline Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd87665b",
   "metadata": {},
   "source": [
    "This visualises the distribution for each point prediction made. Every eighth datapoint is omitted for clarity of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a414726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joypy\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "means_train2, samples_train2, stds_train2 = post.sort_data([means_train[0], samples_train[0], stds_train[0]],sortby=0) \n",
    "skip_every = 8\n",
    "data = pd.DataFrame(samples_train2.squeeze()[:,::skip_every])\n",
    "\n",
    "fig, axes = joypy.joyplot(pd.DataFrame(samples_train2.squeeze()[:,::skip_every]),\n",
    "                          range_style='own', # Limits each subplot to the area where it's non-zero\n",
    "                          #ylabels=False,   # Also turns off horz grid lines if False\n",
    "                          #xlabels=True,\n",
    "                          overlap=0.5,        \n",
    "                          grid='y',        # 'y': Horz grid lines, True: horz and vert\n",
    "                          linewidth=0.5,     # Outlines\n",
    "                          #labels = labels,   # Which y labels to plot (corresponding to horz lines). Doesn't work for some reason\n",
    "                          kind='counts',   # Plotting raw counts rather than estimated density\n",
    "                          #legend=True,   \n",
    "                          figsize=(8,15),\n",
    "                          bins=50, \n",
    "                          fade=True,       # subplots get progressively higher alpha values \n",
    "                          title=f\"Ridge Plot of Training set\\nSkipping every {skip_every} point(s):\\n{data.shape[1]} samples of {len(means_train[0])})\",\n",
    "                          colormap=cm.autumn_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234c7b3",
   "metadata": {},
   "source": [
    "## Show the Distribution of Errors and Uncertainties in each Dataset\n",
    "### Using Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba565506",
   "metadata": {},
   "source": [
    "These plots make a range of summaries about the dataset and predictions.\n",
    "\n",
    "In row major ordering:\n",
    "\n",
    " - Plot 1: The error between each prediction sample and the true value. This outlines the accuracy of the predictions, and the spread of the samples.  \n",
    " - Plot 2: Very similar to Plot 1, except looking at the mean of all samples drawn for each datapoint. This outlines the accuracy of the predictions. \n",
    " - Plot 3: Shows the absolute width of the confidence interval of every data point in each set. This outlines the uncertainty of the predictions.  \n",
    " - Plot 4: Shows the distribution of the predicted values in each dataset. This outlines the performance of the model as well as describing the dataset.\n",
    " - Plot 5: If a confidence interval does not capture the true y value, then how far outside the confidence interval is the y value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070190ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "samples = [samples_val[0], samples_train[0], samples_test[0]]\n",
    "true = [y_val_np[0], y_train_np[0], y_test_np[0]]\n",
    "labels=[\"Validation\", \"Train\", \"Test (OoD)\"]\n",
    "histograms1, statistics1 = post.histogram_stats(samples,\n",
    "                                                true,\n",
    "                                                labels,\n",
    "                                                method=\"SD\",\n",
    "                                                interval=1,\n",
    "                                                dp=.3,\n",
    "                                                bins=100,\n",
    "                                                figsize=(13,9),\n",
    "                                                plot_1_ylim=(0,2),\n",
    "                                                plot_1_xlim=(0,20),\n",
    "                                                plot_2_ylim=(0,2),\n",
    "                                                plot_3_ylim=(0,25),\n",
    "                                                plot_3_xlim=(0,0.5),\n",
    "                                                plot_2_xlim=(-20,10),\n",
    "                                                plot_5_ylim=(0,1),\n",
    "                                                plot_5_xlim=(-40,10))\n",
    "                                                \n",
    "\n",
    "# Save the image to weights and biases\n",
    "if wandb_mode: wandb.log({\"Histograms_output0\":wandb.Image(histograms1)})\n",
    "if wandb_mode: wandb.log({\"Data_output0\":statistics1})\n",
    "    \n",
    "    \n",
    "# Print the individual figures shown in the histograms\n",
    "# import json\n",
    "# print(json.dumps(statistics1, indent=6, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "samples = [samples_val[1], samples_train[1], samples_test[1]]\n",
    "true = [y_val_np[1], y_train_np[1], y_test_np[1]]\n",
    "labels=[\"Validation\", \"Train\", \"Test (OoD)\"]\n",
    "histograms1, statistics1 = post.histogram_stats(samples,\n",
    "                                                true,\n",
    "                                                labels,\n",
    "                                                method=\"SD\",\n",
    "                                                interval=1,\n",
    "                                                dp=.3,\n",
    "                                                bins=100,\n",
    "                                                figsize=(13,9),\n",
    "                                                plot_1_ylim=(0,2),\n",
    "                                                plot_1_xlim=(0,20),\n",
    "                                                plot_2_ylim=(0,2),\n",
    "                                                plot_3_ylim=(0,25),\n",
    "                                                plot_3_xlim=(0,0.5),\n",
    "                                                plot_2_xlim=(-20,10),\n",
    "                                                plot_5_ylim=(0,1),\n",
    "                                                plot_5_xlim=(-40,10))\n",
    "                                                \n",
    "\n",
    "# Save the image to weights and biases\n",
    "if wandb_mode: wandb.log({\"Histograms_output0\":wandb.Image(histograms1)})\n",
    "if wandb_mode: wandb.log({\"Data_output0\":statistics1})\n",
    "    \n",
    "    \n",
    "# Print the individual figures shown in the histograms\n",
    "# import json\n",
    "# print(json.dumps(statistics1, indent=6, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "samples = [samples_val[2], samples_train[2], samples_test[2]]\n",
    "true = [y_val_np[2], y_train_np[2], y_test_np[2]]\n",
    "labels=[\"Validation\", \"Train\", \"Test (OoD)\"]\n",
    "histograms1, statistics1 = post.histogram_stats(samples,\n",
    "                                                true,\n",
    "                                                labels,\n",
    "                                                method=\"SD\",\n",
    "                                                interval=1,\n",
    "                                                dp=.3,\n",
    "                                                bins=100,\n",
    "                                                figsize=(13,9),\n",
    "                                                plot_1_ylim=(0,2),\n",
    "                                                plot_1_xlim=(0,20),\n",
    "                                                plot_2_ylim=(0,2),\n",
    "                                                plot_3_ylim=(0,25),\n",
    "                                                plot_3_xlim=(0,0.5),\n",
    "                                                plot_2_xlim=(-20,10),\n",
    "                                                plot_5_ylim=(0,1),\n",
    "                                                plot_5_xlim=(-40,10))\n",
    "                                                \n",
    "\n",
    "# Save the image to weights and biases\n",
    "if wandb_mode: wandb.log({\"Histograms_output0\":wandb.Image(histograms1)})\n",
    "if wandb_mode: wandb.log({\"Data_output0\":statistics1})\n",
    "    \n",
    "    \n",
    "# Print the individual figures shown in the histograms\n",
    "# import json\n",
    "# print(json.dumps(statistics1, indent=6, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e47e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "samples = [samples_val[3], samples_train[3], samples_test[3]]\n",
    "true = [y_val_np[3], y_train_np[3], y_test_np[3]]\n",
    "labels=[\"Validation\", \"Train\", \"Test (OoD)\"]\n",
    "histograms1, statistics1 = post.histogram_stats(samples,\n",
    "                                                true,\n",
    "                                                labels,\n",
    "                                                method=\"SD\",\n",
    "                                                interval=1,\n",
    "                                                dp=.3,\n",
    "                                                bins=100,\n",
    "                                                figsize=(13,9),\n",
    "                                                plot_1_ylim=(0,2),\n",
    "                                                plot_1_xlim=(0,20),\n",
    "                                                plot_2_ylim=(0,2),\n",
    "                                                plot_3_ylim=(0,25),\n",
    "                                                plot_3_xlim=(0,0.5),\n",
    "                                                plot_2_xlim=(-20,10),\n",
    "                                                plot_5_ylim=(0,1),\n",
    "                                                plot_5_xlim=(-40,10))\n",
    "                                                \n",
    "\n",
    "# Save the image to weights and biases\n",
    "if wandb_mode: wandb.log({\"Histograms_output0\":wandb.Image(histograms1)})\n",
    "if wandb_mode: wandb.log({\"Data_output0\":statistics1})\n",
    "    \n",
    "    \n",
    "# Print the individual figures shown in the histograms\n",
    "# import json\n",
    "# print(json.dumps(statistics1, indent=6, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695e91d4",
   "metadata": {},
   "source": [
    "# Save Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, savename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
